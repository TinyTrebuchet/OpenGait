# Note  : *** the batch_size should be equal to the gpus number at the test phase!!! ***
data_cfg:
  dataset_name: CUSTOM
  dataset_root: /home/tiny/Downloads/MTP/data-360-pkl
  dataset_partition: ./datasets/CUSTOM/CUSTOM.json
  num_workers: 1
  remove_no_gallery: false
  test_dataset_name: CUSTOM

evaluator_cfg:
  enable_float16: false 
  restore_ckpt_strict: true
  restore_hint: 80000
  save_name: FDFormer
  sampler:
    batch_size: 1
    sample_type: all_ordered
    type: InferenceSampler

loss_cfg:
  - loss_term_weight: 1.0
    margin: 0.2
    type: TripletLoss
    log_prefix: triplet
  - loss_term_weight: 1.0
    scale: 1
    type: CrossEntropyLoss
    log_accuracy: true
    label_smooth: false
    log_prefix: softmax

model_cfg:
  model: FDFormer
  channels: [32, 64, 128]
  # number of subjects used in training
  image_size: [64,44]
  frames_num: 36
  class_num: 20000
  SeparateBNNecks:
    class_num: 20000
    in_channels: 128
    parts_num: 64

optimizer_cfg:
  lr: 1.0e-4
  solver: Adam
  weight_decay: 5.0e-4

scheduler_cfg:
  gamma: 0.1
  milestones:
    - 70000
  scheduler: MultiStepLR

trainer_cfg:
  enable_float16: true
  with_test: true
  log_iter: 100
  restore_ckpt_strict: true
  restore_hint: 0
  save_iter: 10000
  save_name: FDFormer
  sync_BN: true
  total_iter: 80000
  sampler:
    batch_shuffle: true
    batch_size:
      - 8
      - 8
    frames_num_fixed: 36
    frames_skip_num: 0
    sample_type: fixed_ordered
    type: TripletSampler
